# ğŸŒ¿ EthnoPharma Cloud â€” AI-Powered Ethnobotany Pipeline (GCP, Cloud Run, Firestore)

EthnoPharma Cloud is a fully automated AI-driven system for discovering, enriching and publishing ethnobotanical plant knowledge.  
It runs 100% serverlessly on **Google Cloud Run**, uses **Firestore** as the main data store, and applies **OpenAI models** to generate structured bilingual content.

This repository contains the production-grade, cleaned version of the system â€” designed for recruiters, engineers and collaborators.

---

## ğŸ§© Features

- **Autonomous plant discovery** (AI-based)
- **Full enrichment pipeline** (sources â†’ narrative â†’ effects â†’ image)
- **Multilingual text generation (RU/EN)**
- **Automatic posting to Telegram (via bot API)**
- **ETL-style modular pipelines**
- **Serverless execution via Cloud Run Jobs & Services**
- **Firestore-based content state machine**
- **Robust normalization, validation, safety rules**
- **Image attribution via iNaturalist**
- **Affiliate link auto-detection (iHerb etc.)**
- **Clean, explicit, maintainable architecture**

---

# ğŸ“ Architecture Overview

```
ethnopharma-cloud/
â”‚
â”œâ”€â”€ src_clean/
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ discover-candidates-clean/    # Cloud Run Job â€” AI-based discovery of new plants
â”‚   â”‚   â””â”€â”€ post-random-clean/            # Cloud Run Service â€” daily posting to Telegram
â”‚   â”‚
â”‚   â”œâ”€â”€ pipeline/                         # Full enrichment pipeline (local or Cloud Run)
â”‚   â”‚   â”œâ”€â”€ steps/                        # 01â€“10 modular steps (find, fetch, enrich, pick imageâ€¦)
â”‚   â”‚   â”œâ”€â”€ services/                     # iNaturalist, affiliate search, image processing
â”‚   â”‚   â”œâ”€â”€ utils/                        # normalization, validation, networking, metadata
â”‚   â”‚   â”œâ”€â”€ config/                       # allowlists, vocabularies, schemas
â”‚   â”‚   â””â”€â”€ tools/                        # audit reports, HTML cleaning, file-safe operations
â”‚
â”œâ”€â”€ tools/                                # Repo-wide operational scripts
â”‚   â”œâ”€â”€ importCandidates.js
â”‚   â”œâ”€â”€ importEffects.js
â”‚   â”œâ”€â”€ import_cards_ready_to_firestore.js
â”‚   â”œâ”€â”€ updateCooldown.js
â”‚   â”œâ”€â”€ reconcile-candidates.js
â”‚   â””â”€â”€ firestore_ping.mjs
â”‚
â””â”€â”€ Dockerfile                            # Cloud Run compatible image for services
```

---

# ğŸš€ Deployment (Google Cloud Run)

### **1. Build container**

```sh
gcloud builds submit --tag gcr.io/$PROJECT_ID/post-random-clean
```

### **2. Deploy service (Telegram posting)**

```sh
gcloud run deploy post-random-clean \
  --image gcr.io/$PROJECT_ID/post-random-clean \
  --platform=managed \
  --region=me-west1 \
  --allow-unauthenticated
```

### **3. Deploy job (discover-candidates)**

```sh
gcloud run jobs deploy discover-candidates-clean \
  --image gcr.io/$PROJECT_ID/discover-candidates-clean \
  --region=me-west1
```

### **4. Cloud Scheduler example (daily 9:00)**

```sh
gcloud scheduler jobs create http telegram-daily \
  --schedule="0 9 * * *" \
  --uri="https://post-random-clean-xxxxx.run.app" \
  --http-method=POST
```

---

# ğŸ›  Local Development

### Install

```sh
npm install
```

### Run posting service locally

```sh
npm run dev:post
```

### Run candidate discovery locally

```sh
npm run dev:discover
```

### Required environment variables

- `GOOGLE_APPLICATION_CREDENTIALS`
- `BOT_TOKEN`
- `CHANNEL_ID`
- OpenAI API keys (pipeline / discovery)

---

# ğŸ§ª Pipeline Breakdown (7 Steps)

Located in: **src_clean/pipeline/steps/**

1. **01_findCandidates** â€” initial candidate detection
2. **02_fetchSources** â€” scrape scientific & ethnobotanical sources
3. **03_enrichNarrative** â€” generate bilingual narrative
4. **04_extractEffects** â€” effect extraction (adaptogens, anxiolytics etc.)
5. **05_pickImage** â€” iNaturalist image + attribution
6. **06_affiliate** â€” detect/store affiliate links
7. **08_qualityGate** â€” rule-based safety & quality checks

---

# ğŸ”§ Operational Tools

Directory: `tools/`

- `updateCooldown.js` â€” bulk update Firestore field `cooldownDays`
- `importCandidates.js` / `importEffects.js` â€” bulk importers
- `firestore_ping.mjs` â€” connection debugging
- `reconcile-candidates.js` â€” detect inconsistencies

These scripts simplify maintenance of large content volumes.

---

# ğŸ“¦ Technologies Used

- Node.js 22
- Google Cloud Run (Jobs + Services)
- Firestore (Native mode)
- Google Cloud Scheduler
- Docker (Cloud Build)
- OpenAI APIs
- iNaturalist API
- Telegram Bot API
- Modular ETL patterns
- Bilingual content handling (RU/EN)

---

# ğŸ“Œ Why This Project Matters (Professional Context)

This repository demonstrates practical experience with:

- serverless cloud architecture,
- asynchronous job orchestration,
- modular ETL-style pipelines,
- Firestore data modeling,
- AI-assisted content generation,
- production-grade deployment with Cloud Run,
- robust multilingual text processing,
- high-volume automated content publishing,
- clean and maintainable codebase.

Designed for scalability and long-term maintainability.

---

# ğŸ“„ License

MIT
